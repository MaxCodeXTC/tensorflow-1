{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimators and Eager Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eager Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Samuel/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.executing_eagerly())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.SkipDataset"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path to datasets\n",
    "train_path = 'data_input/iris_training.csv'\n",
    "test_path = 'data_input/iris_testing.csv'\n",
    "\n",
    "# load datasets, skipping first line as its a header and not an observation\n",
    "trainset = tf.data.TextLineDataset(train_path).skip(1)\n",
    "\n",
    "type(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata describing the text columns\n",
    "COLUMNS = ['SepalLength', 'SepalWidth',\n",
    "           'PetalLength', 'PetalWidth',\n",
    "           'label']\n",
    "FIELD_DEFAULTS = [[0.0], [0.0], [0.0], [0.0], [0]]\n",
    "def _parse_line(line):\n",
    "    # Decode the line into its fields\n",
    "    fields = tf.decode_csv(line, FIELD_DEFAULTS)\n",
    "\n",
    "    # Pack the result into a dictionary\n",
    "    features = dict(zip(COLUMNS,fields))\n",
    "\n",
    "    # Separate the label from the features\n",
    "    label = features.pop('label')\n",
    "\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ({SepalLength: (), SepalWidth: (), PetalLength: (), PetalWidth: ()}, ()), types: ({SepalLength: tf.float32, SepalWidth: tf.float32, PetalLength: tf.float32, PetalWidth: tf.float32}, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "trainset = trainset.map(_parse_line)\n",
    "print(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'PetalLength': TensorShape([]),\n",
       "  'PetalWidth': TensorShape([]),\n",
       "  'SepalLength': TensorShape([]),\n",
       "  'SepalWidth': TensorShape([])},\n",
       " TensorShape([]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'PetalLength': <tf.Tensor: id=35, shape=(), dtype=float32, numpy=5.6>,\n",
       "  'PetalWidth': <tf.Tensor: id=36, shape=(), dtype=float32, numpy=2.2>,\n",
       "  'SepalLength': <tf.Tensor: id=37, shape=(), dtype=float32, numpy=6.4>,\n",
       "  'SepalWidth': <tf.Tensor: id=38, shape=(), dtype=float32, numpy=2.8>},\n",
       " <tf.Tensor: id=39, shape=(), dtype=int32, numpy=2>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.make_one_shot_iterator().next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note is that only native tensorflow models are supported in eager execution mode. Also: while keras models are not yet supported, but Keras layers are. Which means that while you can't use `tf.keras.models.Sequential` yet (see: _3_keras.ipynb_), we could combine layers by hand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
